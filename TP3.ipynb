{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "XYcbTfIwO7pN"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "from keras.utils import to_categorical\n",
        "from keras import backend as K\n",
        "K.set_image_data_format('channels_first')\n",
        "seed = 7\n",
        "np.random.seed(seed)\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import matplotlib.pyplot as  plt\n",
        "from keras.layers import Conv2D,MaxPooling2D,Flatten,Dense,Dropout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Chargement et préparation des données de MNIST:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "zSIU9iaoTqMw"
      },
      "outputs": [],
      "source": [
        "def get_data_mnist() :\n",
        "    #load data\n",
        "    (X_train,y_train),(X_test,y_test)=mnist.load_data()\n",
        "    \n",
        "    # reshape to be [samples][pixels][width][height] \n",
        "    X_train=np.reshape(X_train,(-1,28,28,1))\n",
        "    X_test=np.reshape(X_test,(-1,28,28,1))\n",
        "\n",
        "    #one hot encode outputs\n",
        "    y_train = to_categorical(y_train, num_classes=10)\n",
        "    y_test = to_categorical(y_test, num_classes=10)\n",
        "\n",
        "    num_classes = y_test.shape[1]\n",
        "\n",
        "    return X_train, y_train, X_test, y_test, num_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cj3XHkQkUFLA",
        "outputId": "ce184385-1a50-48f1-ccec-a814b32b2630"
      },
      "outputs": [],
      "source": [
        "X_train, y_train, X_test, y_test, num_classes = get_data_mnist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNc5_4aXUsJC",
        "outputId": "fa778a52-f133-4fc5-a79a-fae535584fd7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dimensions de l'ensemble d'apprentissage (X_train) : (60000, 28, 28, 1)\n",
            "Dimensions de l'ensemble de test (X_test) : (10000, 28, 28, 1)\n",
            "Dimensions de la sortie de l'ensemble d'apprentissage (y_train) : (60000, 10)\n",
            "Dimensions de la sortie de l'ensemble de test (y_test) : (10000, 10)\n",
            "nombre de classe est : 10\n"
          ]
        }
      ],
      "source": [
        "print(\"Dimensions de l'ensemble d'apprentissage (X_train) :\", X_train.shape)\n",
        "print(\"Dimensions de l'ensemble de test (X_test) :\", X_test.shape)\n",
        "print(\"Dimensions de la sortie de l'ensemble d'apprentissage (y_train) :\", y_train.shape)\n",
        "print(\"Dimensions de la sortie de l'ensemble de test (y_test) :\", y_test.shape)\n",
        "print(\"nombre de classe est :\", num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Small CNN :\n",
        "\n",
        "1) Convolution Layer: 64 filtres de taille 3x3 + activation ReLU\n",
        "2) Convolution Layer: 32 filtres de taille 3x3 + activation ReLU\n",
        "3) Flatten Layer\n",
        "4) Dense Layer (Output): couche dense + activation softmax pour la classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "t2rVxuWDjD2P"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/mariem/.local/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, Flatten, Dense\n",
        "\n",
        "def small_model():\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(28, 28, 1)))\n",
        "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Creating the model\n",
        "small_cnn = small_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgCvnyBFWYIz",
        "outputId": "169ff11d-ed00-4751-b3ec-5d624c16ac69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.7787 - loss: 2.0146 - val_accuracy: 0.9411 - val_loss: 0.1999\n",
            "Epoch 2/5\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - accuracy: 0.9516 - loss: 0.1699 - val_accuracy: 0.9543 - val_loss: 0.1640\n",
            "Epoch 3/5\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - accuracy: 0.9645 - loss: 0.1162 - val_accuracy: 0.9557 - val_loss: 0.1468\n",
            "Epoch 4/5\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - accuracy: 0.9716 - loss: 0.0908 - val_accuracy: 0.9588 - val_loss: 0.1408\n",
            "Epoch 5/5\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - accuracy: 0.9751 - loss: 0.0812 - val_accuracy: 0.9674 - val_loss: 0.1077\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7965a7d2d810>"
            ]
          },
          "execution_count": 99,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "small_cnn.fit(X_train,y_train,batch_size=100,epochs=5,validation_data=(X_test,y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "mIhD8VA2Fltx"
      },
      "outputs": [],
      "source": [
        "def print_model_error_rate(model, X_test, y_test):\n",
        "  # Final evaluation of the model\n",
        "  scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "  print(\"Model score : %.2f%%\" % (scores[1]*100))\n",
        "  print(\"Model error rate : %.2f%%\" % (100-scores[1]*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ToKI7E3RxNY",
        "outputId": "680f8a00-0584-4a76-9c8b-a4d650ea0c80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model score : 96.74%\n",
            "Model error rate : 3.26%\n"
          ]
        }
      ],
      "source": [
        "print_model_error_rate(small_cnn, X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-O0CE3WSwHh"
      },
      "source": [
        "### Modification de la fonction get_data_mnist() (Ajouter la normalisation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "2Z6RtDYtR0lx"
      },
      "outputs": [],
      "source": [
        "def get_data_mnist() :\n",
        "    #load data\n",
        "    (X_train,y_train),(X_test,y_test)=mnist.load_data()\n",
        "    # reshape to be [samples][pixels][width][height]\n",
        "    X_train=np.reshape(X_train,(-1,28,28,1))\n",
        "    X_test=np.reshape(X_test,(-1,28,28,1))\n",
        "\n",
        "    #Normalisation\n",
        "    X_train = X_train/255\n",
        "    X_test = X_test/255\n",
        "    #one hot encode outputs\n",
        "    y_train = to_categorical(y_train, num_classes=10)\n",
        "    y_test = to_categorical(y_test, num_classes=10)\n",
        "\n",
        "    num_classes = y_test.shape[1]\n",
        "\n",
        "    return X_train, y_train, X_test, y_test, num_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMmDSceWUtq-",
        "outputId": "29326406-5c16-486e-bef0-6e10a0076468"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.9786 - loss: 0.0686 - val_accuracy: 0.9662 - val_loss: 0.1199\n",
            "Epoch 2/5\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.9774 - loss: 0.0714 - val_accuracy: 0.9696 - val_loss: 0.1168\n",
            "Epoch 3/5\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - accuracy: 0.9817 - loss: 0.0654 - val_accuracy: 0.9663 - val_loss: 0.1357\n",
            "Epoch 4/5\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - accuracy: 0.9822 - loss: 0.0603 - val_accuracy: 0.9716 - val_loss: 0.1064\n",
            "Epoch 5/5\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 15ms/step - accuracy: 0.9834 - loss: 0.0528 - val_accuracy: 0.9736 - val_loss: 0.1092\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7965a783fe50>"
            ]
          },
          "execution_count": 103,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "small_cnn .fit(X_train,y_train,batch_size=100,epochs=5,validation_data=(X_test,y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMgS7-lRUwbZ",
        "outputId": "bcab3a56-8c32-47fe-ac15-02e27b9f1025"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model score : 97.36%\n",
            "Model error rate : 2.64%\n"
          ]
        }
      ],
      "source": [
        "print_model_error_rate(small_cnn , X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OieFzI9uU8Nx"
      },
      "source": [
        "Le taux d'erreur a diminué aprés normalisation des données :\n",
        "\n",
        "Elle est utilisée pour :\n",
        "- Accélerer la convergence\n",
        "- Améliorer la performance des modèles \n",
        "\n",
        "Ceci en rendant les gradients du réseau moins variables, ce qui facilite la stabilisation du processus d'apprentissage lors des ajustements des poids par l'algorithme de rétropropagation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgAybwN4VzoG"
      },
      "source": [
        "# Medium_CNN :\n",
        "\n",
        "1) Convolution Layer: 32 filtres de 5x5 + activation ReLU.\n",
        "2) Max Pooling Layer\n",
        "3) Dropout Layer\n",
        "4) Flatten Layer\n",
        "5) Dense Layer: Première couche dense avec 128 neurones + activation ReLU.\n",
        "6) Dense Layer (Output): Comme dans le Small CNN, une couche de sortie avec softmax pour la classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "o9eBN8HhUxj_"
      },
      "outputs": [],
      "source": [
        "def medium_model():\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, kernel_size=(5, 5), activation='relu', padding='same', input_shape=(28, 28, 1)))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), data_format='channels_last'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "6cMIFdxOWnW0"
      },
      "outputs": [],
      "source": [
        "medium_cnn  = medium_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqediBs1Wr5G",
        "outputId": "49ea0a11-ad0f-4ffd-a5b6-16ac298bd2f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.6689 - loss: 4.6692 - val_accuracy: 0.9089 - val_loss: 0.3321\n",
            "Epoch 2/10\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.8888 - loss: 0.3991 - val_accuracy: 0.9335 - val_loss: 0.2341\n",
            "Epoch 3/10\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - accuracy: 0.9206 - loss: 0.2780 - val_accuracy: 0.9475 - val_loss: 0.1907\n",
            "Epoch 4/10\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 27ms/step - accuracy: 0.9364 - loss: 0.2190 - val_accuracy: 0.9536 - val_loss: 0.1586\n",
            "Epoch 5/10\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - accuracy: 0.9460 - loss: 0.1812 - val_accuracy: 0.9642 - val_loss: 0.1204\n",
            "Epoch 6/10\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.9518 - loss: 0.1584 - val_accuracy: 0.9653 - val_loss: 0.1149\n",
            "Epoch 7/10\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9571 - loss: 0.1397 - val_accuracy: 0.9643 - val_loss: 0.1200\n",
            "Epoch 8/10\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - accuracy: 0.9600 - loss: 0.1296 - val_accuracy: 0.9684 - val_loss: 0.1066\n",
            "Epoch 9/10\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9627 - loss: 0.1211 - val_accuracy: 0.9667 - val_loss: 0.1152\n",
            "Epoch 10/10\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9634 - loss: 0.1196 - val_accuracy: 0.9728 - val_loss: 0.0908\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7965a72b0bb0>"
            ]
          },
          "execution_count": 107,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "medium_cnn.fit(X_train,y_train,batch_size=100,epochs=10,validation_data=(X_test,y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OEMmuphXfk0",
        "outputId": "e488b530-a454-4084-80ab-b11c58ca1a3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model score : 97.28%\n",
            "Model error rate : 2.72%\n"
          ]
        }
      ],
      "source": [
        "print_model_error_rate(medium_cnn, X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Les résultats indiquent que l'ajout de couches de pooling et de dropout, ainsi qu'une augmentation de la capacité de la première couche dense, contribuent positivement à la performance du modèle dans des tâches de reconnaissance d'images comme la classification des chiffres manuscrits du MNIST. \n",
        "\n",
        "- Max Pooling Layer: aide à réduire la dimensionnalité de la représentation des entrées => concentrer le réseau sur les caractéristiques les plus saillantes des images => améliorer la capacité du réseau à généraliser à partir des données d'entraînement.\n",
        "\n",
        "- Dropout Layer: aide à prévenir le surapprentissage (utile dans un contexte où le modèle est potentiellement plus complexe).\n",
        "\n",
        "- Première Couche Dense plus Grande: Avec 128 neurones, cette couche permet au Medium CNN d'avoir une capacité accrue pour apprendre des représentations plus complexes des données => particulièrement bénéfique dans un ensemble de données comme MNIST."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xe29hyRbY4XL"
      },
      "source": [
        "# Large_CNN :\n",
        "1) Convolution Layer: 30 filtres de 5x5 + activation ReLu\n",
        "2) Max Pooling Layer\n",
        "3) Convolution Layer: 15 filtres de 3x3 + activation ReLU\n",
        "4) Max Pooling Layer\n",
        "5) Dropout Layer\n",
        "6) Flatten Layer\n",
        "7) Dense Layer: 128 neurones + activation ReLU\n",
        "8) Dense Layer: Une seconde couche dense avec 50 neurones + activation ReLU pour une classification plus fine\n",
        "9) Dense Layer (Output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "oxe7wp37Xh17"
      },
      "outputs": [],
      "source": [
        "def large_model():\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(30, kernel_size=(5, 5), activation='relu', input_shape=(28, 28, 1), padding='same'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2),data_format='channels_last'))\n",
        "    model.add(Conv2D(15, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dense(50, activation='relu'))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "MEtbIC8QZKDL"
      },
      "outputs": [],
      "source": [
        "large_cnn = large_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHyc3Hg-ZMuF",
        "outputId": "c5bfc2ee-d65a-4fb1-cb7d-fd54f43d9cba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.6796 - loss: 1.4950 - val_accuracy: 0.9471 - val_loss: 0.1837\n",
            "Epoch 2/10\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.9341 - loss: 0.2203 - val_accuracy: 0.9605 - val_loss: 0.1310\n",
            "Epoch 3/10\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - accuracy: 0.9474 - loss: 0.1689 - val_accuracy: 0.9681 - val_loss: 0.1119\n",
            "Epoch 4/10\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - accuracy: 0.9593 - loss: 0.1314 - val_accuracy: 0.9663 - val_loss: 0.1145\n",
            "Epoch 5/10\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - accuracy: 0.9626 - loss: 0.1201 - val_accuracy: 0.9703 - val_loss: 0.1003\n",
            "Epoch 6/10\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - accuracy: 0.9661 - loss: 0.1071 - val_accuracy: 0.9730 - val_loss: 0.0917\n",
            "Epoch 7/10\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - accuracy: 0.9672 - loss: 0.1017 - val_accuracy: 0.9761 - val_loss: 0.0807\n",
            "Epoch 8/10\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.9719 - loss: 0.0894 - val_accuracy: 0.9762 - val_loss: 0.0808\n",
            "Epoch 9/10\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - accuracy: 0.9741 - loss: 0.0814 - val_accuracy: 0.9769 - val_loss: 0.0781\n",
            "Epoch 10/10\n",
            "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - accuracy: 0.9732 - loss: 0.0822 - val_accuracy: 0.9799 - val_loss: 0.0679\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7965a6ff88b0>"
            ]
          },
          "execution_count": 111,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "large_cnn.fit(X_train,y_train,batch_size=100,epochs=10,validation_data=(X_test,y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcy17WBVZpmT",
        "outputId": "dbad59cc-f155-47f7-dac3-441e7b9c5dd3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model score : 97.99%\n",
            "Model error rate : 2.01%\n"
          ]
        }
      ],
      "source": [
        "print_model_error_rate(large_cnn, X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0iJ4waIaMMb"
      },
      "source": [
        "## Conclusion: \n",
        "\n",
        "Le \"meilleur\" modèle dépendra de divers facteurs:\n",
        "\n",
        "Bien sûr, voici une conclusion condensée sous forme de points clés pour une synthèse claire et directe :\n",
        "\n",
        "- **Complexité de la tâche** : Utiliser des modèles plus complexes pour des tâches qui exigent la capture de caractéristiques détaillées.\n",
        "- **Taille du jeu de données** : Opter pour des modèles plus avancés pour de grands jeux de données afin d'éviter le sous-apprentissage.\n",
        "- **Ressources disponibles** : Choisir le modèle en fonction des ressources computationnelles et du temps disponible pour l'entraînement.\n",
        "\n",
        "## Choix du model: \n",
        "- **Small Model** : Convient pour des tâches simples et des jeux de données plus petits; rapide à entraîner.\n",
        "- **Medium Model** : Bon compromis, incorporant des techniques de régularisation sans une complexité excessive.\n",
        "- **Large Model** : Meilleur pour les tâches complexes et les grandes données; plus précis mais nécessite plus de ressources.\n",
        "- **Performance sur MNIST** : Le Large Model a montré la meilleure précision, mais il est important de considérer les coûts de ressources et de temps.\n",
        "\n",
        "Cette liste de points permet une prise de décision rapide et informée en fonction des exigences spécifiques de la tâche et des ressources disponibles.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKL1xkHKZ6iD"
      },
      "source": [
        "# Sauvegarde et chargements des modèles Keras :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "geuAFS3dZrlU"
      },
      "outputs": [],
      "source": [
        "# This function saves a model on the drive using two files: a json and a h5\n",
        "def save_keras_model(model, filename):\n",
        "    model_json = model.to_json()\n",
        "    with open(filename + \".json\", \"w\") as json_file:\n",
        "        json_file.write(model_json)\n",
        "    model.save_weights(filename + \".weights.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "py3dUPekbCRR"
      },
      "outputs": [],
      "source": [
        "save_keras_model(small_cnn, 'file')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "JXCryq-mbgAk"
      },
      "outputs": [],
      "source": [
        "save_keras_model(medium_cnn, 'file2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "y7D1cI_ubgJH"
      },
      "outputs": [],
      "source": [
        "save_keras_model(large_cnn, 'file3')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "VSuWziT2ajzq"
      },
      "outputs": [],
      "source": [
        "from keras.models import model_from_json\n",
        "\n",
        "# This function loads a model from two files : a json and a h5\n",
        "def load_keras_model(filename):\n",
        "  json_file = open(filename+\".json\", 'r')\n",
        "  loaded_model_json = json_file.read()\n",
        "  json_file.close()\n",
        "  loaded_model = model_from_json(loaded_model_json)\n",
        "  loaded_model.load_weights(filename+\".weights.h5\")\n",
        "  return loaded_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1hJ4Jxhawv5",
        "outputId": "a344be10-d6c3-499a-8ad3-88e98914fddd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Sequential name=sequential_9, built=True>"
            ]
          },
          "execution_count": 118,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "load_keras_model('file')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGGlbU-IbOGX",
        "outputId": "96bf3f25-0069-4574-f937-e704ed291e8d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Sequential name=sequential_10, built=True>"
            ]
          },
          "execution_count": 119,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "load_keras_model('file2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6ohkGn8bpn5",
        "outputId": "b974d07d-45e9-4370-adc5-484f791d580b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Sequential name=sequential_11, built=True>"
            ]
          },
          "execution_count": 120,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "load_keras_model('file3')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "VfW3TYp0idmZ"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing import image\n",
        "\n",
        "def test_image(path, model,c):\n",
        "  img_path = path\n",
        "  img = image.load_img(img_path, target_size=(28, 28), color_mode='grayscale')\n",
        "  img_array = image.img_to_array(img)\n",
        "  img_array = np.expand_dims(img_array, axis=0)\n",
        "  reshaped_img_array = np.reshape(img_array, (-1, 28, 28, 1))\n",
        "  predictions = model.predict(reshaped_img_array)\n",
        "  predicted_class = np.argmax(predictions)\n",
        "  print(\"Predicted Class :\", predicted_class)\n",
        "  print(\"Image Class :\", c)\n",
        "  if(predicted_class==c):\n",
        "    print(\"correct prediction\")\n",
        "  else :\n",
        "    print('incorrect prediction')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyHTsSlbijtU",
        "outputId": "2a2e4fca-2c29-4498-b8f7-59f4f7ac2792"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
            "Predicted Class : 2\n",
            "Image Class : 2\n",
            "correct prediction\n"
          ]
        }
      ],
      "source": [
        "test_image('./content/2.jfif', medium_cnn,2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FU3b9g6-j9dV",
        "outputId": "c43dcd0a-9712-423a-e8ac-f33f041fa958"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7965a6641c60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7965a6641c60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
            "Predicted Class : 1\n",
            "Image Class : 1\n",
            "correct prediction\n"
          ]
        }
      ],
      "source": [
        "test_image('./content/1.jfif', large_cnn,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOOP6FWtkDKj",
        "outputId": "88c4819e-4394-46d5-e3e9-66003127fd2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7965a7dcaef0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7965a7dcaef0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
            "Predicted Class : 8\n",
            "Image Class : 3\n",
            "incorrect prediction\n"
          ]
        }
      ],
      "source": [
        "test_image('./content/3.jfif', small_cnn,3)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
